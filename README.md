# Machine Learning & Security Seminar

Welcome to Machine Learning & Security Seminar, organized by Samuel Conte Professor [Xiangyu Zhang](https://www.cs.purdue.edu/homes/xyzhang/), in [Department of Computer Science](https://www.cs.purdue.edu/) at [Purdue University](https://www.purdue.edu/).

[[Fall 2022]](#Fall-2022), [[Summer 2022]](#Summer-2022), [[Spring 2022]](#Spring-2022), [[Fall 2021]](#Fall-2021), [[Summer 2021]](#Summer-2021)

### Fall 2022
This semester the seminar is co-organized by Kaiyuan Zhang.
| Date | Discussion Leader | Title | Source |
| :------| :---------| :-------| :-------|
| 08/26 | Shengwei An | [Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks](https://www.usenix.org/conference/usenixsecurity22/presentation/li-huiying) | USENIX 2022 |
| 09/02 | Yingqi Liu | [Not All Poisons are Created Equal: Robust Training against Data Poisoning](https://proceedings.mlr.press/v162/yang22j.html) | ICML 2022 |
| 09/09 | Canceled |  |  |
| 09/16 | Canceled |  |  |
| 09/23 | Kaiyuan Zhang | [Auditing Privacy Defenses in Federated Learning via Generative Gradient Leakage](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Auditing_Privacy_Defenses_in_Federated_Learning_via_Generative_Gradient_Leakage_CVPR_2022_paper.pdf) | CVPR 2022 |
| 09/30 | Zian Su | [Repository-Level Prompt Generation for Large Language Models of Code](https://arxiv.org/pdf/2206.12839.pdf) | arXiv 2022 |
| 10/07 | Xuan Chen | [Robust Reinforcement Learning with Alternating Training of Learned Adversaries](https://arxiv.org/pdf/2101.08452.pdf) | ICLR 2021 |
| 10/14 | Canceled |  |  |
| 10/21 | Lu Yan | [Data Isotopes for Data Provenance in DNNs](https://arxiv.org/pdf/2208.13893.pdf) | arXiv 2022 |

### Summer 2022
This semester the seminar is co-organized by Kaiyuan Zhang.
| Date | Discussion Leader | Title | Source |
| :------| :---------| :-------| :-------|
| 05/20 | Yingqi Liu | Practice talk |  |
|  | Guanhong Tao | Practice talk |  |
| 05/27 | Siyuan Cheng | [Class-Disentanglement and Applications in Adversarial Detection and Defense](https://proceedings.neurips.cc//paper/2021/file/8606f35ec6c77858dfb80a385d0d1151-Paper.pdf) | NeurIPS 2021 |
| 06/03 | Canceled |  |  |
| 06/10 | Guanhong Tao | Backdoor defense |  |
| 06/17 | Canceled |  |  |
| 06/24 | Kaiyuan Zhang | [CAFE: Catastrophic Data Leakage in Vertical Federated Learning](https://arxiv.org/pdf/2110.15122.pdf) | NeurIPS 2021 |
| 07/01 | Zian Su | [Black-Box Tuning for Language-Model-as-a-Service](https://arxiv.org/pdf/2201.03514.pdf) | ICML 2022 |
| 07/08 | Xuan Chen | [Robust Deep Reinforcement Learning through Adversarial Loss](https://papers.nips.cc/paper/2021/file/dbb422937d7ff56e049d61da730b3e11-Paper.pdf) | NeurIPS 2021 |
| 07/15 | Lu Yan | [Fight Poison with Poison: Detecting Backdoor Poison Samples via Decoupling Benign Correlations](https://arxiv.org/pdf/2205.13616.pdf) | arXiv 2022 |
|  |  | [Circumventing Backdoor Defenses That Are Based on Latent Separability](https://arxiv.org/pdf/2205.13613.pdf) | arXiv 2022 |
| 07/22 | Guanhong Tao | [Excess Capacity and Backdoor Poisoning](https://arxiv.org/pdf/2109.00685.pdf) | NeurIPS 2021 |
| 07/29 | Canceled |  |  |
| 08/05 | Guangyu Shen | [SPECTRE: Defending Against Backdoor Attacks Using Robust Statistics](https://arxiv.org/pdf/2104.11315.pdf) | ICML 2021 |
| 08/12 | Siyuan Cheng | [FLAME: Taming Backdoors in Federated Learning](https://arxiv.org/pdf/2101.02281.pdf) | USENIX 2022 |
| 08/19 | Canceled |  |  |

### Spring 2022
This semester the seminar is co-organized by Kaiyuan Zhang.
| Date | Discussion Leader | Title | Source |
| :------| :---------| :-------| :-------|
| 01/07 | Zian Su | [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/pdf/2111.06377.pdf) | arXiv 2021 |
| 01/14 | Canceled |  |  |
| 01/21 | Shiwei Feng | [Adversarial Neuron Pruning Purifies Backdoored Deep Models](https://arxiv.org/pdf/2110.14430.pdf) | NeurIPS 2021 |
| 01/28 | Canceled |  |  |
| 02/04 | Shengwei An | [Get a Model! Model Hijacking Attack Against Machine Learning Models](https://arxiv.org/abs/2111.04394) | NDSS 2022 |
| 02/11 | Siyuan Cheng | [Anti-Backdoor Learning: Training Clean Models on Poisoned Data](https://proceedings.neurips.cc/paper/2021/file/7d38b1e9bd793d3f45e0e212a729a93c-Paper.pdf) | NeurIPS 2021 |
| 02/18 | Guanhong Tao | [Traceback of Data Poisoning Attacks in Neural Networks](https://arxiv.org/pdf/2110.06904.pdf) | arXiv 2021 |
| 02/25 | Canceled |  |  |
| 03/04 | Kaiyuan Zhang | [Label Inference Attacks Against Vertical Federated Learning](https://www.usenix.org/system/files/sec22summer_fu.pdf) | USENIX 2022 |
| 03/11 | Yingqi Liu | [Back to the Drawing Board: A Critical Evaluation of Poisoning Attacks on Production Federated Learning](https://arxiv.org/pdf/2108.10241.pdf) | S&P 2022 |
| 03/18 | Xuan Chen | [Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL](https://openreview.net/references/pdf?id=rnz8C_E3-q) | ICLR 2022 |
| 03/25 | Canceled |  |  |
| 04/01 | Canceled |  |  |
| 04/08 | Guangyu Shen | Backdoor defense |  |
| 04/15 | Qiuling Xu | Few-shot learning in adversarial learning |  |
| 04/22 | Shengwei An | Practice talk: [MIRROR: Model Inversion for Deep Learning Network with High Fidelity](https://www.ndss-symposium.org/wp-content/uploads/2022-335-paper.pdf) | NDSS 2022 |
|   |  | Model inversion defense |  |
| 04/29 | Canceled |  |  |
| 05/06 | Canceled |  |  |
| 05/13 | Canceled |  |  |

### Fall 2021
This semester the seminar is co-organized by Kaiyuan Zhang.
| Date | Discussion Leader | Title | Source |
| :------| :---------| :-------| :-------|
| 08/27 | Zhiyuan Cheng | [Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack](https://www.usenix.org/system/files/sec21-sato.pdf) | USENIX 2021 |
| 09/03 | Canceled |  |  |
| 09/10 | Guangyu Shen | [Adversarial Attacks are Reversible with Natural Supervision](https://arxiv.org/abs/2103.14222) | ICCV 2021 |
|   |   | [Poisoning and Backdooring Contrastive Learning](https://arxiv.org/pdf/2106.09667.pdf) | arXiv 2021 |
| 09/17 | Xuan Chen | [Adversarial Policies: Attacking Deep Reinforcement Learning](https://arxiv.org/pdf/1905.10615.pdf) | ICLR 2020 |
|   |   | [BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning](https://www.ijcai.org/proceedings/2021/0509.pdf) | IJCAI 2021	|
| 09/24 | Guanhong Tao | [BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning](https://arxiv.org/pdf/2108.00352.pdf) | S&P 2022 |
| 10/01 | Qiuling Xu | [Stronger and Faster Wasserstein Adversarial Attacks](https://arxiv.org/abs/2008.02883) | ICML 2020 |
| 10/08 | Canceled |  |  |
| 10/15 | Zian Su | [Prefix-Tuning: Optimizing Continuous Prompt for Generation](https://arxiv.org/pdf/2101.00190.pdf) | ACL 2021 |
| 10/22 | Siyuan Cheng | Backdoor detection |  |
| 10/29 | Canceled |  |  |
| 11/05 | Guanhong Tao | Backdoor defense |  |
| 11/12 | Canceled |  |  |
| 11/19 | Shengwei An | Neural code editing |  |
| 11/26 | Canceled |  |  |
| 12/03 | Kaiyuan Zhang | [Model-Contrastive Federated Learning](https://arxiv.org/pdf/2103.16257.pdf) | CVPR 2021 |
| 12/10 | Yingqi Liu | [Hidden Backdoors in Human-Centric Language Models](https://arxiv.org/pdf/2105.00164.pdf) | CCS 2021 |
|   |   | [Backdoor Pre-trained Models Can Transfer to All](https://arxiv.org/pdf/2111.00197.pdf) | CCS 2021 |
| 12/17 | Guangyu Shen | [Rethinking Stealthiness of Backdoor Attack against NLP Models](https://aclanthology.org/2021.acl-long.431.pdf) | ACL 2021 |

### Summer 2021
This semester the seminar is co-organized by Kaiyuan Zhang.
| Date | Discussion Leader | Title | Source |
| :------| :---------| :-------| :-------|
| 05/13 | Guanhong Tao | [What Doesn't Kill You Makes You Robust(er): Adversarial Training against Poisons and Backdoors](https://arxiv.org/pdf/2102.13624.pdf) | arXiv 2021 |
|            |            |  [PatchGuard: A Provably Robust Defense against Adversarial Patches via Small Receptive Fields and Masking](https://arxiv.org/pdf/2005.10884.pdf) | arXiv 2021 |
| 05/21 | Yingqi Liu | [Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks](https://arxiv.org/pdf/2008.04495.pdf) | arXiv 2021 |
|            |            |  [Deep Partition Aggregation: Provable Defenses against General Poisoning Attacks](https://openreview.net/pdf?id=YUGG2tFuPM) | ICLR 2021 |
| 05/28 | Canceled |  |  |
| 06/04 | Guangyu Shen | [T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification](https://www.usenix.org/conference/usenixsecurity21/presentation/azizi) | USENIX 2021 |
| 06/11 | Kaiyuan Zhang | [Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for Federated Learning](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-3_24498_paper.pdf) | NDSS 2021 |
| 06/18 | Shengwei An | [Detecting and Simulating Artifacts in GAN Fake Images](https://arxiv.org/pdf/1907.06515.pdf) | WIFS 2019 |
|       |          | [CNN-generated images are surprisingly easy to spot... for now](https://arxiv.org/pdf/1912.11035.pdf) | CVPR 2020 |
| 06/25 | Yingqi Liu | [Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger](https://arxiv.org/pdf/2105.12400.pdf) | ACL 2021 |
|       |          | [Turn the Combination Lock:Learnable Textual Backdoor Attacks via Word Substitution](https://arxiv.org/pdf/2106.06361.pdf) | arXiv 2021 |
| 07/02 | Guanhong Tao | Backdoor learning |  |
| 07/09 | Guangyu Shen | [See through Gradients: Image Batch Recovery via GradInversion](https://arxiv.org/pdf/2104.07586.pdf) | CVPR 2021 |
| 07/16 | Canceled |  |  |
| 07/23 | Kaiyuan Zhang | [How To Backdoor Federated Learning](http://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a.pdf) | PMLR 2020 |
|  |  | [Attack of the Tails: Yes, You Really Can Backdoor Federated Learning](https://papers.nips.cc/paper/2020/file/b8ffa41d4e492f0fad2f13e29e1762eb-Paper.pdf) | NeurIPS 2020 |
| 07/30 | Shengwei An | [Improving the Efficiency and Robustness of Deepfakes Detection through Precise Geometric Features](https://arxiv.org/pdf/2104.04480.pdf) | CVPR 2021 |
| 08/06 | Yingqi Liu | [Detecting AI Trojans Using Meta Neural Analysis](https://arxiv.org/pdf/1910.03137.pdf) | S&P 2021 |
| 08/13 | Guanhong Tao | [Double-Cross Attacks: Subverting Active Learning Systems](https://www.usenix.org/system/files/sec21-vicarte.pdf) |  USENIX 2021 |