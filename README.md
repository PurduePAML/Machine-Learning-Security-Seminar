# Machine Learning & Security Seminar

Welcome to the Machine Learning & Security Seminar.

[[Spring 2022]](#Spring-2022), [[Fall 2021]](#Fall-2021), [[Summer 2021]](#Summer-2021)

### Spring 2022
| Date | Discussion Leader | Title | Source |
| :------| :---------| :-------| :-------|
| 01/07 | Zian Su | [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/pdf/2111.06377.pdf) | arXiv 2021 |
| 01/14 | Canceled |  |  |
| 01/21 | Shiwei Feng | [Adversarial Neuron Pruning Purifies Backdoored Deep Models](https://arxiv.org/pdf/2110.14430.pdf) | NeurIPS 2021 |
| 01/28 | Canceled |  |  |
| 02/04 | Shengwei An | [Get a Model! Model Hijacking Attack Against Machine Learning Models](https://arxiv.org/abs/2111.04394) | NDSS 2022 |
| 02/11 | Siyuan Cheng | [Anti-Backdoor Learning: Training Clean Models on Poisoned Data](https://proceedings.neurips.cc/paper/2021/file/7d38b1e9bd793d3f45e0e212a729a93c-Paper.pdf) | NeurIPS 2021 |
| 02/18 | Guanhong Tao | [Traceback of Data Poisoning Attacks in Neural Networks](https://arxiv.org/pdf/2110.06904.pdf) | arXiv 2021 |
| 02/25 | Canceled |  |  |
| 03/04 | Kaiyuan Zhang | [Label Inference Attacks Against Vertical Federated Learning](https://www.usenix.org/system/files/sec22summer_fu.pdf) | USENIX 2022 |
| 03/11 | Yingqi Liu | [Back to the Drawing Board: A Critical Evaluation of Poisoning Attacks on Production Federated Learning](https://arxiv.org/pdf/2108.10241.pdf) | S&P 2022 |

### Fall 2021
| Date | Discussion Leader | Title | Source |
| :------| :---------| :-------| :-------|
| 08/27 | Zhiyuan Cheng | [Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack](https://www.usenix.org/system/files/sec21-sato.pdf) | USENIX 2021 |
| 09/03 | Canceled |  |  |
| 09/10 | Guangyu Shen | [Adversarial Attacks are Reversible with Natural Supervision](https://arxiv.org/abs/2103.14222) | ICCV 2021 |
|   |   | [Poisoning and Backdooring Contrastive Learning](https://arxiv.org/pdf/2106.09667.pdf) | arXiv 2021 |
| 09/17 | Xuan Chen | [Adversarial Policies: Attacking Deep Reinforcement Learning](https://arxiv.org/pdf/1905.10615.pdf) | ICLR 2020 |
|   |   | [BACKDOORL: Backdoor Attack against Competitive Reinforcement Learning](https://www.ijcai.org/proceedings/2021/0509.pdf) | IJCAI 2021	|
| 09/24 | Guanhong Tao | [BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning](https://arxiv.org/pdf/2108.00352.pdf) | S&P 2022 |
| 10/01 | Qiuling Xu | [Stronger and Faster Wasserstein Adversarial Attacks](https://arxiv.org/abs/2008.02883) | ICML 2020 |
| 10/08 | Canceled |  |  |
| 10/15 | Zian Su | [Prefix-Tuning: Optimizing Continuous Prompt for Generation](https://arxiv.org/pdf/2101.00190.pdf) | ACL 2021 |
| 10/22 | Siyuan Cheng | Backdoor detection |  |
| 10/29 | Canceled |  |  |
| 11/05 | Guanhong Tao | Backdoor defense |  |
| 11/12 | Canceled |  |  |
| 11/19 | Shengwei An | Neural code editing |  |
| 11/26 | Canceled |  |  |
| 12/03 | Kaiyuan Zhang | [Model-Contrastive Federated Learning](https://arxiv.org/pdf/2103.16257.pdf) | CVPR 2021 |
| 12/10 | Yingqi Liu | [Hidden Backdoors in Human-Centric Language Models](https://arxiv.org/pdf/2105.00164.pdf) | CCS 2021 |
|   |   | [Backdoor Pre-trained Models Can Transfer to All](https://arxiv.org/pdf/2111.00197.pdf) | CCS 2021 |
| 12/17 | Guangyu Shen | [Rethinking Stealthiness of Backdoor Attack against NLP Models](https://aclanthology.org/2021.acl-long.431.pdf) | ACL 2021 |

### Summer 2021
| Date | Discussion Leader | Title | Source |
| :------| :---------| :-------| :-------|
| 05/13 | Guanhong Tao | [What Doesn't Kill You Makes You Robust(er): Adversarial Training against Poisons and Backdoors](https://arxiv.org/pdf/2102.13624.pdf) | arXiv 2021 |
|            |            |  [PatchGuard: A Provably Robust Defense against Adversarial Patches via Small Receptive Fields and Masking](https://arxiv.org/pdf/2005.10884.pdf) | arXiv 2021 |
| 05/21 | Yingqi Liu | [Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks](https://arxiv.org/pdf/2008.04495.pdf) | arXiv 2021 |
|            |            |  [Deep Partition Aggregation: Provable Defenses against General Poisoning Attacks](https://openreview.net/pdf?id=YUGG2tFuPM) | ICLR 2021 |
| 05/28 | Canceled |  |  |
| 06/04 | Guangyu Shen | [T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification](https://www.usenix.org/conference/usenixsecurity21/presentation/azizi) | USENIX 2021 |
| 06/11 | Kaiyuan Zhang | [Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for Federated Learning](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-3_24498_paper.pdf) | NDSS 2021 |
| 06/18 | Shengwei An | [Detecting and Simulating Artifacts in GAN Fake Images](https://arxiv.org/pdf/1907.06515.pdf) | WIFS 2019 |
|       |          | [CNN-generated images are surprisingly easy to spot... for now](https://arxiv.org/pdf/1912.11035.pdf) | CVPR 2020 |
| 06/25 | Yingqi Liu | [Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger](https://arxiv.org/pdf/2105.12400.pdf) | ACL 2021 |
|       |          | [Turn the Combination Lock:Learnable Textual Backdoor Attacks via Word Substitution](https://arxiv.org/pdf/2106.06361.pdf) | arXiv 2021 |
| 07/02 | Guanhong Tao | Backdoor learning |  |
| 07/09 | Guangyu Shen | [See through Gradients: Image Batch Recovery via GradInversion](https://arxiv.org/pdf/2104.07586.pdf) | CVPR 2021 |
| 07/16 | Canceled |  |  |
| 07/23 | Kaiyuan Zhang | [How To Backdoor Federated Learning](http://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a.pdf) | PMLR 2020 |
|  |  | [Attack of the Tails: Yes, You Really Can Backdoor Federated Learning](https://papers.nips.cc/paper/2020/file/b8ffa41d4e492f0fad2f13e29e1762eb-Paper.pdf) | NeurIPS 2020 |
| 07/30 | Shengwei An | [Improving the Efficiency and Robustness of Deepfakes Detection through Precise Geometric Features](https://arxiv.org/pdf/2104.04480.pdf) | CVPR 2021 |
| 08/06 | Yingqi Liu | [Detecting AI Trojans Using Meta Neural Analysis](https://arxiv.org/pdf/1910.03137.pdf) | S&P 2021 |
| 08/13 | Guanhong Tao | [Double-Cross Attacks: Subverting Active Learning Systems](https://www.usenix.org/system/files/sec21-vicarte.pdf) |  USENIX 2021 |